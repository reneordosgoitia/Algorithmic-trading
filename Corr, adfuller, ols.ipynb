#!/usr/bin/env python
# coding: utf-8

# In[1]:


pip install python-binance


# In[2]:


import pandas as pd
import numpy as np
from binance import Client
import datetime as dt
import math
get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (11, 5)  #set default figure size
import matplotlib
matplotlib.style.use('seaborn')
# client configuration
api_key = 'xxx' 
api_secret = 'xxxx'
client = Client(api_key, api_secret)


# In[3]:


tickers = pd.DataFrame(client.get_all_tickers()) #client.get_all_tickers() this is going to help us to obtain all the tickers.
list_symbols = tickers["symbol"]


# In[4]:


filt = []
word = str("USDT")
for i in list_symbols:

  if word in i: # here we select only XXXUSDT pairs.

    filt.append(i)

filt1 = filt[:50] #filter for 50 pairs


# In[5]:


interval="15m" #here we select the timeframe we are going to use in order to do the analysis.
Client.KLINE_INTERVAL_15MINUTE 
data = [pd.DataFrame(client.get_historical_klines(i, interval, "15 jan,2023")) for i in filt1 ]

for i in range(len(data)-1,0,-1):
  
    if data[i].empty: #here we clean the data, deleting those with empty data.
     del data[i]
    
    data[i]["symbol"] = filt1[i]
  
    


# In[6]:


data[0].columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol',"taker_quote_vol", "ignore"]
data[0]["symbol"] = filt1[0]


# In[7]:


for i in range(len(data)):
  data[i].columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol',"taker_quote_vol", "ignore","symbol"]
  data[i].index = [dt.datetime.fromtimestamp(i/1000.0) for i in data[i].close_time]


# In[8]:


full_data = []

full_data = pd.concat(data)


# In[9]:


full_data = pd.DataFrame(full_data.set_index(['symbol',full_data.index])["close"])


# In[10]:


symbols = list(set(full_data.index.get_level_values(0)))


# In[11]:


len(symbols)


# In[12]:


cl = full_data.loc["BTCUSDT"][["close"]]


# In[13]:


cl.rename({"close": "BTCUSDT"}, axis = 1, inplace= True)


# In[14]:


for i in symbols:
  if i !="BTCUSDT":
    cl[i]= full_data.loc[i][["close"]]


# In[51]:


import seaborn as sns
import datetime
idx = pd.IndexSlice
import statsmodels.api as sm
from statsmodels.regression.linear_model import OLS
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.stattools import coint


# In[52]:


cl = cl.astype(float)


# In[53]:


def find_cointegrated_pairs(data): #here we construct the cointegration function for many pairs.
    #n = data.shape[1]
    n = len(symbols)
    pvalue_matrix = np.ones((n, n))
    keys = data.keys()
    pairs = []
    for i in range(n):
        for j in range(i+1, n):
            result = coint(data[keys[i]], data[keys[j]])
            pvalue_matrix[i, j] = result[1]
            if result[1] < 0.05:
                pairs.append((keys[i], keys[j]))
    return pvalue_matrix, pairs


# In[54]:


pvalues, pairs = find_cointegrated_pairs(cl)  


# In[55]:


pv = pd.DataFrame(pvalues)
pv.columns = cl.columns
pv.index = cl.columns


# In[56]:


pv1 = pv.unstack().sort_values()


# In[57]:


pv1


# In[58]:


pv2 = pv1[pv1 <= 0.05]


# In[59]:


len(pv2)


# In[60]:


pv2 = pv2.reset_index()


# In[61]:


#Stationary analysis with DFA

#keys = fil.keys()
pvalue_matrix = pd.DataFrame(index=cl.index)
pvalue_matrix.index = cl.index
for i in range(len(pv2)):
           
    names3 = pv2["level_0"].loc[i],pv2["level_1"].loc[i]
    result = adfuller(cl[pv2['level_0'].loc[i]] / cl[pv2['level_1'].loc[i]])[1]
    #pvalue_matrix[('fil[i].columns,fil[j].columns'), fil.index ] = result[0]
            
    pvalue_matrix[ names3] = np.array(result, dtype=object)
            #if result[1] < 0.05:


# In[85]:


#OLS Beta calculation and cointegration analysis with DFA


adf_matrix = pd.DataFrame(index=cl.index)
spread_matrix = pd.DataFrame(index= cl.index)
beta_matrix= pd.DataFrame(index=cl.index)
ratio= pd.DataFrame(index=cl.index)
ma30= pd.DataFrame(index=cl.index)
std30= pd.DataFrame(index=cl.index)


for i in range(len(pv2)):
           
    names3 = pv2["level_0"].loc[i],pv2["level_1"].loc[i]
    beta_result = sm.OLS(cl[pv2['level_0'].loc[i]], cl[pv2['level_1'].loc[i]]).fit().params[0]
    spread = cl[pv2['level_0'].loc[i]] - cl[pv2['level_1'].loc[i]]*beta_result
    adf = adfuller(spread, maxlag =1)
    spread_matrix[ names3] = np.array(spread, dtype=object)
    adf_matrix[ names3] = np.array(adf[1], dtype=object)
    beta_matrix[ names3] = np.array(beta_result, dtype=object)
    
    
    ratio[ names3] = np.array(cl[pv2['level_0'].loc[i]] / cl[pv2['level_1'].loc[i]], dtype = object)
    
    
 


# # We used the correlation analysis result and the ADF filter to create a new spread data set, which includes the OLS beta calculation

# In[100]:


zscoreld = ((ratio-ratio.mean())/np.std(ratio)).dropna() #In this step, we calculate the zscore of the spread data created previously.


# In[101]:


zscore2 = zscoreld


# In[102]:


zscore2


# In[103]:


zscore2.columns =  spread_matrix.columns


# In[104]:


adf_f = adf_matrix[adf_matrix< 0.05].iloc[0].dropna() 
#In this process, we only choose pairs where the null hypothesis has been rejected


# In[105]:


zcore_f = zscoreld[adf_f.index]


# In[106]:


zcore_f


# In[ ]:




